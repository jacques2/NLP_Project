{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706bd4b0",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment 1 ‚Äî Sexism Detection (EXIST 2023 Task 2)\n",
    "\n",
    "**Group members:** Jacopo Francesco Amoretti, Roberto Frabetti, Ivo Rambaldi \n",
    "\n",
    "---\n",
    "\n",
    "## Delivery checklist\n",
    "- [ ] Task 1 ‚Äî Corpus (majority vote aggregation, EN filter, label encoding)\n",
    "- [ ] Task 2 ‚Äî Data Cleaning (emoji/hashtag/mention/url/symbols/quotes + lemmatization)\n",
    "- [ ] Task 3 ‚Äî Text Encoding (GloVe + OOV handling + embedding matrix)\n",
    "- [ ] Task 4 ‚Äî Models (BiLSTM baseline and stacked)\n",
    "- [ ] Task 5 ‚Äî Training & Evaluation (‚â• 3 seeds, macro F1/Prec/Rec, avg ¬± std)\n",
    "- [ ] Task 6 ‚Äî Transformers (Twitter-roBERTa-base-hate + Trainer)\n",
    "- [ ] Task 7 ‚Äî Error Analysis (error patterns, confusion/PR, examples)\n",
    "- [ ] Task 8 ‚Äî Report (summary of results, figures, metrics table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e68b9",
   "metadata": {},
   "source": [
    "\n",
    "## Setup\n",
    "\n",
    "Run this once at the beginning. It sets seeds, libraries, and project paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee4bfcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Basic imports ===\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization/plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# Optional: progress bar\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    tqdm = lambda x: x\n",
    "\n",
    "# Seed and device\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Project paths (adjust as needed)\n",
    "DATA_DIR = Path('data')          # Should contain: train.json, val.json, test.json\n",
    "GLOVE_DIR = Path('glove')        # Files like glove.6B.100d.txt (or others)\n",
    "ARTIFACTS_DIR = Path('artifacts')# Save vocab, mappings, embedding matrix, etc.\n",
    "MODELS_DIR = Path('models')\n",
    "RESULTS_DIR = Path('results')\n",
    "\n",
    "for d in [ARTIFACTS_DIR, MODELS_DIR, RESULTS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Setup complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a70aa95",
   "metadata": {},
   "source": [
    "\n",
    "# Task 1 ‚Äî Corpus\n",
    "\n",
    "**Goal**  \n",
    "1. Load `train/val/test` JSON into DataFrames.  \n",
    "2. Majority voting on `labels_task2` ‚Üí new column `label` (drop items without a clear majority).  \n",
    "3. Filter `lang == 'en'`.  \n",
    "4. Keep only: `id_EXIST`, `lang`, `tweet`, `label`.  \n",
    "5. Encode `label` with mapping:\n",
    "```python\n",
    "label2id = {'-': 0, 'DIRECT': 1, 'JUDGEMENTAL': 2, 'REPORTED': 3}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685b788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# == Majority vote on a list of labels ==\n",
    "from collections import Counter\n",
    "\n",
    "def majority_vote(labels):\n",
    "    cnt = Counter(labels)\n",
    "    top = cnt.most_common()\n",
    "    if len(top) == 0:\n",
    "        return None, False\n",
    "    if len(top) > 1 and top[0][1] == top[1][1]:\n",
    "        return None, False  # no clear majority\n",
    "    return top[0][0], True\n",
    "\n",
    "label2id = {'-': 0, 'DIRECT': 1, 'JUDGEMENTAL': 2, 'REPORTED': 3}\n",
    "id2label = {v:k for k,v in label2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# == Load JSON into DataFrame ==\n",
    "train_path = Path('data') / 'train.json'\n",
    "val_path   = Path('data') / 'val.json'\n",
    "test_path  = Path('data') / 'test.json'\n",
    "\n",
    "def load_exist_json(path: Path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    return df\n",
    "\n",
    "df_train_raw = load_exist_json(train_path)\n",
    "df_val_raw   = load_exist_json(val_path)\n",
    "df_test_raw  = load_exist_json(test_path)\n",
    "\n",
    "print('Train raw:', df_train_raw.shape, '| Val raw:', df_val_raw.shape, '| Test raw:', df_test_raw.shape)\n",
    "df_train_raw.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# == Majority voting on labels_task2 and filtering ==\n",
    "def apply_majority_and_filter(df):\n",
    "    mv_labels = []\n",
    "    keep_mask = []\n",
    "    for _, row in df.iterrows():\n",
    "        mv, ok = majority_vote(row['labels_task2'])\n",
    "        mv_labels.append(mv)\n",
    "        keep_mask.append(ok)\n",
    "    df = df.copy()\n",
    "    df['label'] = mv_labels\n",
    "    df = df[pd.Series(keep_mask).values]\n",
    "    return df\n",
    "\n",
    "df_train_mv = apply_majority_and_filter(df_train_raw)\n",
    "df_val_mv   = apply_majority_and_filter(df_val_raw)\n",
    "df_test_mv  = apply_majority_and_filter(df_test_raw)\n",
    "\n",
    "print('After majority vote ->',\n",
    "      'Train:', df_train_mv.shape, 'Val:', df_val_mv.shape, 'Test:', df_test_mv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# == EN filter and column selection ==\n",
    "KEEP_COLS = ['id_EXIST', 'lang', 'tweet', 'label']\n",
    "\n",
    "def filter_and_select(df):\n",
    "    df = df[df['lang'] == 'en'].copy()\n",
    "    df = df[KEEP_COLS].copy()\n",
    "    return df\n",
    "\n",
    "df_train = filter_and_select(df_train_mv)\n",
    "df_val   = filter_and_select(df_val_mv)\n",
    "df_test  = filter_and_select(df_test_mv)\n",
    "\n",
    "print('EN only ->', 'Train:', df_train.shape, 'Val:', df_val.shape, 'Test:', df_test.shape)\n",
    "df_train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25271b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# == Label encoding ==\n",
    "def encode_labels(df):\n",
    "    df = df.copy()\n",
    "    df['label_id'] = df['label'].map(label2id)\n",
    "    return df\n",
    "\n",
    "df_train = encode_labels(df_train)\n",
    "df_val   = encode_labels(df_val)\n",
    "df_test  = encode_labels(df_test)\n",
    "\n",
    "print(df_train['label'].value_counts())\n",
    "df_train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402502c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Save post-Task1 datasets for quick reuse ==\n",
    "df_train[['id_EXIST','lang','tweet','label','label_id']].to_csv('results/train_task1.csv', index=False)\n",
    "df_val[['id_EXIST','lang','tweet','label','label_id']].to_csv('results/val_task1.csv', index=False)\n",
    "df_test[['id_EXIST','lang','tweet','label','label_id']].to_csv('results/test_task1.csv', index=False)\n",
    "print(\"Saved post-Task1 datasets to 'results/' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2719fb",
   "metadata": {},
   "source": [
    "\n",
    "# Task 2 ‚Äî Data Cleaning\n",
    "\n",
    "**Requirements**  \n",
    "- Remove: emojis, hashtags (`#...`), mentions (`@user`), URLs, special characters/symbols, typographic quotes.  \n",
    "- Lemmatization (English).\n",
    "\n",
    "> **Note:** you may use `spaCy` with `en_core_web_sm` or `nltk`/`stanza`. Below is a spaCy-based pipeline; if the model is not installed, see the comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb741167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# == Text cleaning: basic regex ==\n",
    "\n",
    "import re\n",
    "\n",
    "URL_RE = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "MENTION_RE = re.compile(r'@\\w+')\n",
    "HASHTAG_RE = re.compile(r'#\\w+')\n",
    "EMOJI_RE = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "SPECIAL_QUOTES_REPLACEMENTS = {\n",
    "    '‚Äú': '\"', '‚Äù': '\"', '‚Äò': \"'\", '‚Äô': \"'\",\n",
    "    '¬´': '\"', '¬ª': '\"', '‚Ä¶': '...'\n",
    "}\n",
    "\n",
    "def normalize_quotes(text: str):\n",
    "    for k, v in SPECIAL_QUOTES_REPLACEMENTS.items():\n",
    "        text = text.replace(k, v)\n",
    "    return text\n",
    "\n",
    "def basic_clean(text: str):\n",
    "    text = normalize_quotes(text)\n",
    "    text = URL_RE.sub(' ', text)\n",
    "    text = MENTION_RE.sub(' ', text)\n",
    "    text = HASHTAG_RE.sub(' ', text)\n",
    "    text = EMOJI_RE.sub(' ', text)\n",
    "    text = re.sub(r\"[^0-9A-Za-z'\\.,!\\?\\s]\", ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "print(basic_clean(\"Check this: https://ex.com @user #hashtag üòÖ ‚Äúquote‚Äù ‚Äî symbols!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# == Lemmatization with spaCy (graceful fallback) ==\n",
    "USE_SPACY = True\n",
    "try:\n",
    "    import spacy\n",
    "    try:\n",
    "        nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
    "    except Exception:\n",
    "        nlp = None\n",
    "        print(\"Warning: spaCy model 'en_core_web_sm' not installed. Install it and re-run.\")\n",
    "except Exception:\n",
    "    USE_SPACY = False\n",
    "    nlp = None\n",
    "    print('spaCy not available; skipping lemmatization or use another library.')\n",
    "\n",
    "def lemmatize_en(texts):\n",
    "    if nlp is None:\n",
    "        return texts\n",
    "    docs = nlp.pipe(texts, batch_size=512)\n",
    "    out = []\n",
    "    for doc in docs:\n",
    "        lemmas = [t.lemma_.lower() for t in doc if not t.is_space]\n",
    "        out.append(' '.join(lemmas))\n",
    "    return out\n",
    "\n",
    "def apply_clean_and_lemma(df, text_col='tweet'):\n",
    "    df = df.copy()\n",
    "    df['clean'] = df[text_col].astype(str).apply(basic_clean)\n",
    "    df['clean_lemma'] = lemmatize_en(df['clean'].tolist())\n",
    "    return df\n",
    "\n",
    "df_train = apply_clean_and_lemma(df_train, 'tweet')\n",
    "df_val   = apply_clean_and_lemma(df_val, 'tweet')\n",
    "df_test  = apply_clean_and_lemma(df_test, 'tweet')\n",
    "\n",
    "df_train[['tweet','clean','clean_lemma']].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c84a95",
   "metadata": {},
   "source": [
    "\n",
    "# Task 3 ‚Äî Text Encoding (GloVe + OOV)\n",
    "\n",
    "**Goals**  \n",
    "- Tokenize `df_train['clean_lemma']` (or `clean` if you skip lemmatization).  \n",
    "- Build vocabulary: **all tokens from train** (or union `train ‚à™ GloVe`).  \n",
    "- Load GloVe and create `embedding_matrix` with:\n",
    "  - tokens in GloVe ‚Üí pretrained vector\n",
    "  - OOV tokens (in train but not in GloVe) ‚Üí custom vector (e.g., random)\n",
    "  - unknown tokens in val/test ‚Üí `<UNK>` with a static embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TOKEN_RE = re.compile(r\"\\w+('[\\w]+)?\")\n",
    "\n",
    "def simple_tokenize(text):\n",
    "    return TOKEN_RE.findall(text.lower())\n",
    "\n",
    "def build_vocab_from_train(texts, min_freq=1):\n",
    "    from collections import Counter\n",
    "    c = Counter()\n",
    "    for t in texts:\n",
    "        for tok in simple_tokenize(t):\n",
    "            c[tok] += 1\n",
    "    vocab = {tok for tok, f in c.items() if f >= min_freq}\n",
    "    return vocab, c\n",
    "\n",
    "train_texts = df_train['clean_lemma'] if 'clean_lemma' in df_train.columns else df_train['clean']\n",
    "vocab_set, freq = build_vocab_from_train(train_texts.tolist(), min_freq=1)\n",
    "print('Vocab size (train):', len(vocab_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMB_DIM = 100\n",
    "GLOVE_FILE = Path('glove') / f'glove.6B.{EMB_DIM}d.txt'\n",
    "\n",
    "def load_glove(path):\n",
    "    emb = {}\n",
    "    if not path.exists():\n",
    "        print(f'WARNING: GloVe file not found: {path}. Will initialize OOV randomly.')\n",
    "        return emb\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.rstrip().split(' ')\n",
    "            w = parts[0]\n",
    "            vec = np.asarray(parts[1:], dtype=np.float32)\n",
    "            emb[w] = vec\n",
    "    print('Loaded GloVe vectors:', len(emb))\n",
    "    return emb\n",
    "\n",
    "glove = load_glove(GLOVE_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3341c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USE_UNION_WITH_GLOVE = False\n",
    "\n",
    "SPECIAL_TOKENS = ['<PAD>', '<UNK>']\n",
    "token_list = sorted(vocab_set)\n",
    "if USE_UNION_WITH_GLOVE and len(glove) > 0:\n",
    "    token_list = sorted(set(token_list).union(set(glove.keys())))\n",
    "\n",
    "itos = SPECIAL_TOKENS + token_list\n",
    "stoi = {tok:i for i, tok in enumerate(itos)}\n",
    "\n",
    "def rand_vec(d):\n",
    "    return np.random.normal(0, 0.1, size=(d,)).astype(np.float32)\n",
    "\n",
    "embedding_matrix = np.zeros((len(itos), EMB_DIM), dtype=np.float32)\n",
    "embedding_matrix[stoi['<PAD>']] = np.zeros(EMB_DIM, dtype=np.float32)\n",
    "embedding_matrix[stoi['<UNK>']] = rand_vec(EMB_DIM)\n",
    "\n",
    "oov_count = 0\n",
    "for tok in token_list:\n",
    "    idx = stoi[tok]\n",
    "    if tok in glove:\n",
    "        embedding_matrix[idx] = glove[tok]\n",
    "    else:\n",
    "        embedding_matrix[idx] = rand_vec(EMB_DIM)\n",
    "        oov_count += 1\n",
    "\n",
    "print('Total vocab:', len(itos), '| OOV (train vs GloVe):', oov_count)\n",
    "\n",
    "np.save(Path('artifacts') / 'embedding_matrix.npy', embedding_matrix)\n",
    "import pandas as pd\n",
    "pd.Series(itos).to_csv(Path('artifacts') / 'itos.csv', index=False)\n",
    "pd.Series(stoi).to_csv(Path('artifacts') / 'stoi.csv')\n",
    "print('Saved embedding_matrix.npy, itos.csv, stoi.csv to artifacts/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_LEN = 64\n",
    "PAD_ID = stoi['<PAD>']\n",
    "UNK_ID = stoi['<UNK>']\n",
    "\n",
    "def encode_text(text, max_len=MAX_LEN):\n",
    "    toks = simple_tokenize(text)\n",
    "    ids = [stoi.get(t, UNK_ID) for t in toks]\n",
    "    if len(ids) < max_len:\n",
    "        ids = ids + [PAD_ID] * (max_len - len(ids))\n",
    "    else:\n",
    "        ids = ids[:max_len]\n",
    "    return ids\n",
    "\n",
    "def encode_dataframe(df, text_col='clean_lemma'):\n",
    "    X = np.vstack([encode_text(t) for t in df[text_col].tolist()])\n",
    "    y = df['label_id'].values.astype(int)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = encode_dataframe(df_train)\n",
    "X_val,   y_val   = encode_dataframe(df_val)\n",
    "X_test,  y_test  = encode_dataframe(df_test)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66d6c3",
   "metadata": {},
   "source": [
    "\n",
    "# Task 4 ‚Äî Model Definition (BiLSTM)\n",
    "\n",
    "**Required**  \n",
    "- **Baseline:** Bidirectional LSTM + final Dense.  \n",
    "- **Stacked:** add a second BiLSTM on top.  \n",
    "- Keras example below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "EMBED_TRAINABLE = False\n",
    "\n",
    "def build_baseline_bilstm(vocab_size, emb_dim, embedding_matrix, max_len=64):\n",
    "    inp = layers.Input(shape=(max_len,), name='input_ids')\n",
    "    emb = layers.Embedding(input_dim=vocab_size,\n",
    "                           output_dim=emb_dim,\n",
    "                           weights=[embedding_matrix],\n",
    "                           trainable=EMBED_TRAINABLE,\n",
    "                           mask_zero=True,\n",
    "                           name='encoder_embedding')(inp)\n",
    "    x = layers.Bidirectional(layers.LSTM(128))(emb)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    out = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    model = models.Model(inp, out, name='bilstm_baseline')\n",
    "    return model\n",
    "\n",
    "def build_stacked_bilstm(vocab_size, emb_dim, embedding_matrix, max_len=64):\n",
    "    inp = layers.Input(shape=(max_len,), name='input_ids')\n",
    "    emb = layers.Embedding(input_dim=vocab_size,\n",
    "                           output_dim=emb_dim,\n",
    "                           weights=[embedding_matrix],\n",
    "                           trainable=EMBED_TRAINABLE,\n",
    "                           mask_zero=True,\n",
    "                           name='encoder_embedding')(inp)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(emb)\n",
    "    x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    model = models.Model(inp, out, name='bilstm_stacked')\n",
    "    return model\n",
    "\n",
    "VOCAB_SIZE = embedding_matrix.shape[0]\n",
    "EMB_DIM = embedding_matrix.shape[1]\n",
    "\n",
    "baseline = build_baseline_bilstm(VOCAB_SIZE, EMB_DIM, embedding_matrix, MAX_LEN)\n",
    "stacked  = build_stacked_bilstm(VOCAB_SIZE, EMB_DIM, embedding_matrix, MAX_LEN)\n",
    "\n",
    "baseline.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f5c05",
   "metadata": {},
   "source": [
    "\n",
    "# Task 5 ‚Äî Training & Evaluation\n",
    "\n",
    "Train with ‚â• 3 seeds, evaluate on validation (macro F1/Precision/Recall), and report mean ¬± std.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934f4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def train_and_eval(model_fn, X_tr, y_tr, X_va, y_va, seeds=[1337, 2025, 42], epochs=5, batch_size=64):\n",
    "    histories = []\n",
    "    scores = []\n",
    "    for s in seeds:\n",
    "        tf.keras.utils.set_random_seed(s)\n",
    "        model = model_fn(VOCAB_SIZE, EMB_DIM, embedding_matrix, MAX_LEN)\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        h = model.fit(X_tr, y_tr, validation_data=(X_va, y_va),\n",
    "                      epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "        histories.append(h.history)\n",
    "        y_pred = np.argmax(model.predict(X_va), axis=1)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(y_va, y_pred, average='macro', zero_division=0)\n",
    "        scores.append({'seed': s, 'precision': prec, 'recall': rec, 'f1': f1})\n",
    "    return histories, pd.DataFrame(scores)\n",
    "\n",
    "# Example (commented):\n",
    "# hist_base, df_scores_base = train_and_eval(build_baseline_bilstm, X_train, y_train, X_val, y_val)\n",
    "# df_scores_base, df_scores_base.mean(), df_scores_base.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde4c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_predictions(y_true, y_pred, labels_map=id2label):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    df_rep = pd.DataFrame(report).T\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=sorted(labels_map.keys()))\n",
    "    return df_rep, cm\n",
    "\n",
    "def plot_confusion_matrix(cm, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest')\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97566a65",
   "metadata": {},
   "source": [
    "\n",
    "# Task 6 ‚Äî Transformers (Twitter-roBERTa-base-hate)\n",
    "\n",
    "Model: **cardiffnlp/twitter-roberta-base-hate**  \n",
    "- Tokenize with HF tokenizer, prepare `Dataset`, use `Trainer` with macro F1, evaluate on test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dddf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Skeleton for HF Trainer (commented for offline environments)\n",
    "# from datasets import Dataset\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# MODEL_NAME = \"cardiffnlp/twitter-roberta-base-hate\"\n",
    "\n",
    "# def to_hf_dataset(df, text_col='clean_lemma'):\n",
    "#     return Dataset.from_pandas(df[[text_col, 'label_id']].rename(columns={text_col:'text','label_id':'label'}))\n",
    "\n",
    "# ds_train = to_hf_dataset(df_train)\n",
    "# ds_val   = to_hf_dataset(df_val)\n",
    "# ds_test  = to_hf_dataset(df_test)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# def tokenize_fn(ex):\n",
    "#     return tokenizer(ex['text'], truncation=True, padding='max_length', max_length=64)\n",
    "# ds_train = ds_train.map(tokenize_fn, batched=True)\n",
    "# ds_val   = ds_val.map(tokenize_fn, batched=True)\n",
    "# ds_test  = ds_test.map(tokenize_fn, batched=True)\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=4)\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     preds = logits.argmax(axis=-1)\n",
    "#     prec, rec, f1, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "#     return {'macro_f1': f1, 'macro_precision': prec, 'macro_recall': rec}\n",
    "\n",
    "# args = TrainingArguments(\n",
    "#     output_dir='hf_outputs',\n",
    "#     evaluation_strategy='epoch',\n",
    "#     save_strategy='epoch',\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=32,\n",
    "#     per_device_eval_batch_size=64,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model='macro_f1',\n",
    "#     logging_steps=50,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset=ds_train,\n",
    "#     eval_dataset=ds_val,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# # trainer.train()\n",
    "# # eval_results = trainer.evaluate(ds_test)\n",
    "# # eval_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e199bd1f",
   "metadata": {},
   "source": [
    "\n",
    "# Task 7 ‚Äî Error Analysis\n",
    "\n",
    "Suggestions: confusion matrix for the best model, per-class Precision/Recall table, typical misclassified examples, comments on OOV and imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example (fill after training):\n",
    "# y_true = y_val\n",
    "# y_pred = y_pred_val\n",
    "# err_idx = np.where(y_true != y_pred)[0][:20]\n",
    "# df_errors = df_val.iloc[err_idx][['tweet','clean_lemma','label','label_id']].copy()\n",
    "# df_errors['pred_label'] = [id2label[i] for i in y_pred[err_idx]]\n",
    "# df_errors.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
